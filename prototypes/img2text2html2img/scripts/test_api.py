#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
from openai import OpenAI

# API é…ç½®
BASE_URL = "https://api.openai-next.com/v1/"
API_KEY = "sk-K9B2ccVeW4VdAcobD53b16E06b104aA1B5A82593FdFb2557"
CHAT_MODEL = "gpt-3.5-turbo"  # èŠå¤©æ¨¡å‹
IMAGE_MODEL = "flux-pro"  # å›¾åƒç”Ÿæˆæ¨¡å‹

def call_with_retry(func, max_retries=3, base_delay=5):
    """å¸¦é‡è¯•çš„ API è°ƒç”¨"""
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if "429" in str(e) or "RateLimitError" in str(type(e).__name__):
                wait_time = base_delay * (2 ** attempt)
                print(f"é€Ÿç‡é™åˆ¶ï¼Œ{wait_time}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            else:
                raise
    raise Exception(f"é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥")

def test_chat():
    """æµ‹è¯• AI çš„å¯¹è¯åŠŸèƒ½"""
    try:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY
        )
        
        print(f"æ­£åœ¨è¿æ¥: {BASE_URL}")
        print(f"ä½¿ç”¨æ¨¡å‹: {CHAT_MODEL}\n")
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯ï¼ˆå¸¦é‡è¯•ï¼‰
        def make_request():
            return client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"},
                    {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
                ],
                temperature=0.7
            )

        response = call_with_retry(make_request)
        
        # æ˜¾ç¤ºå“åº”
        print("=" * 50)
        print("AI å›å¤:")
        print("=" * 50)
        print(response.choices[0].message.content)
        print("=" * 50)
        print(f"\nä½¿ç”¨ token æ•°: {response.usage.total_tokens}")
        print(f"  - è¾“å…¥: {response.usage.prompt_tokens}")
        print(f"  - è¾“å‡º: {response.usage.completion_tokens}")
        
        return True
        
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False

def test_image_generation():
    """æµ‹è¯• Flux å›¾åƒç”ŸæˆåŠŸèƒ½"""
    try:
        client = OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY
        )

        print(f"æ­£åœ¨è¿æ¥: {BASE_URL}")
        print(f"ä½¿ç”¨æ¨¡å‹: {IMAGE_MODEL}\n")

        prompt = "ä¸€åªå¯çˆ±çš„æ©˜çŒ«ååœ¨çª—å°ä¸Šçœ‹çª—å¤–çš„é›¨"
        print(f"ç”Ÿæˆæç¤ºè¯: {prompt}\n")

        # æ–¹æ³•1: å°è¯•æ ‡å‡† images.generate ç«¯ç‚¹
        print("å°è¯•æ–¹æ³•1: images.generate ç«¯ç‚¹...")
        try:
            def make_image_request():
                return client.images.generate(
                    model=IMAGE_MODEL,
                    prompt=prompt,
                    n=1
                )
            response = call_with_retry(make_image_request, max_retries=5, base_delay=10)
            image_url = response.data[0].url
            print(f"æˆåŠŸ! å›¾åƒ URL: {image_url}")
            _save_image(image_url)
            return True
        except Exception as e1:
            print(f"æ–¹æ³•1 å¤±è´¥: {e1}\n")

        # æ–¹æ³•2: é€šè¿‡ chat completions è°ƒç”¨ï¼ˆæŸäº›ä»£ç†ä½¿ç”¨æ­¤æ–¹å¼ï¼‰
        print("å°è¯•æ–¹æ³•2: chat.completions ç«¯ç‚¹...")
        try:
            def make_chat_request():
                return client.chat.completions.create(
                    model=IMAGE_MODEL,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
            response = call_with_retry(make_chat_request, max_retries=5, base_delay=10)
            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦æœ‰å›¾åƒ URL
            content = response.choices[0].message.content
            print(f"å“åº”å†…å®¹: {content[:500] if len(content) > 500 else content}")

            # å°è¯•æå– URL
            import re
            urls = re.findall(r'https?://[^\s\)\"\']+\.(?:png|jpg|jpeg|webp)', content, re.IGNORECASE)
            if urls:
                print(f"\næ‰¾åˆ°å›¾åƒ URL: {urls[0]}")
                _save_image(urls[0])
                return True
            else:
                print("å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒ URL")
                return True  # è‡³å°‘è°ƒç”¨æˆåŠŸäº†
        except Exception as e2:
            print(f"æ–¹æ³•2 å¤±è´¥: {e2}\n")

        print("æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†")
        return False

    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False

def _save_image(image_url):
    """ä¸‹è½½å¹¶ä¿å­˜å›¾åƒ"""
    if image_url:
        import urllib.request
        output_path = "generated_image.png"
        print(f"\næ­£åœ¨ä¸‹è½½å›¾åƒåˆ°: {output_path}")
        urllib.request.urlretrieve(image_url, output_path)
        print(f"å›¾åƒå·²ä¿å­˜åˆ°: {output_path}")

def list_models():
    """åˆ—å‡º API å¯ç”¨çš„æ¨¡å‹"""
    try:
        client = OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY
        )

        print(f"æ­£åœ¨æŸ¥è¯¢: {BASE_URL}")
        print("è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...\n")

        models = client.models.list()

        print("=" * 60)
        print("å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
        print("=" * 60)

        # æŒ‰æ¨¡å‹ç±»å‹åˆ†ç»„
        chat_models = []
        image_models = []
        other_models = []

        for model in models.data:
            model_id = model.id.lower()
            if any(x in model_id for x in ['gpt', 'claude', 'llama', 'qwen', 'glm', 'deepseek']):
                chat_models.append(model.id)
            elif any(x in model_id for x in ['flux', 'dall', 'stable', 'midjourney', 'sd']):
                image_models.append(model.id)
            else:
                other_models.append(model.id)

        if chat_models:
            print("\nğŸ“ èŠå¤©æ¨¡å‹:")
            for m in sorted(chat_models):
                print(f"   - {m}")

        if image_models:
            print("\nğŸ¨ å›¾åƒæ¨¡å‹:")
            for m in sorted(image_models):
                print(f"   - {m}")

        if other_models:
            print("\nğŸ“¦ å…¶ä»–æ¨¡å‹:")
            for m in sorted(other_models)[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                print(f"   - {m}")
            if len(other_models) > 20:
                print(f"   ... è¿˜æœ‰ {len(other_models) - 20} ä¸ªæ¨¡å‹")

        print("=" * 60)
        print(f"å…± {len(models.data)} ä¸ªæ¨¡å‹")

        return True

    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False

def interactive_chat():
    """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
    client = OpenAI(
        base_url=BASE_URL,
        api_key=API_KEY
    )
    
    print(f"å·²è¿æ¥åˆ°: {BASE_URL}")
    print(f"ä½¿ç”¨æ¨¡å‹: {CHAT_MODEL}")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºå¯¹è¯\n")
    
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"}
    ]
    
    while True:
        user_input = input("\nä½ : ")
        
        if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
            print("å†è§ï¼")
            break
        
        if not user_input.strip():
            continue
        
        messages.append({"role": "user", "content": user_input})
        
        try:
            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=messages,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content
            print(f"\nAI: {ai_response}")
            
            messages.append({"role": "assistant", "content": ai_response})
            
        except Exception as e:
            print(f"é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        mode = sys.argv[1]
        if mode == "interactive":
            interactive_chat()
        elif mode == "image":
            print("æµ‹è¯• Flux å›¾åƒç”Ÿæˆ...\n")
            if test_image_generation():
                print("\nå›¾åƒç”Ÿæˆæµ‹è¯•æˆåŠŸï¼")
        elif mode == "models":
            list_models()
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("å¯ç”¨æ¨¡å¼: interactive, image, models")
    else:
        print("æ‰§è¡ŒèŠå¤©æµ‹è¯•...\n")
        if test_chat():
            print("\næµ‹è¯•æˆåŠŸï¼")
            print("\næç¤º:")
            print("  - è¿è¡Œ 'python test_api.py interactive' è¿›å…¥äº¤äº’å¼å¯¹è¯æ¨¡å¼")
            print("  - è¿è¡Œ 'python test_api.py image' æµ‹è¯• Flux å›¾åƒç”Ÿæˆ")
            print("  - è¿è¡Œ 'python test_api.py models' æŸ¥çœ‹å¯ç”¨æ¨¡å‹åˆ—è¡¨")
