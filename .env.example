# App_Test_Agent 环境配置模板
# 复制此文件为 .env 并填入实际值

# ==================== VLM API 配置（必需）====================

# VLM API Key（用于 UI 分析、语义理解、风格提取）
# 支持 OpenAI 兼容接口
VLM_API_KEY=your-vlm-api-key-here

# VLM API 端点
VLM_API_URL=https://api.openai-next.com/v1/chat/completions

# VLM 模型名称
VLM_MODEL=gpt-4o

# ==================== DashScope API 配置（可选）====================

# DashScope API Key（用于 AI 图像生成）
# 用于：异常弹窗生成、区域加载图标生成
DASHSCOPE_API_KEY=your-dashscope-key-here

# ==================== 模型配置 ====================

# 结构提取模型（用于 Stage 2 语义过滤）
STRUCTURE_MODEL=qwen-vl-max

# VL 模型（视觉语言模型，img2text2html2img 项目使用）
VL_MODEL=qwen-vl-max

# LLM 模型（用于 HTML 生成，img2text2html2img 项目使用）
LLM_MODEL=qwen3-235b-a22b

# ==================== OmniParser 配置 ====================

# 推理设备：cuda 或 cpu
OMNIPARSER_DEVICE=cuda

# 模型路径（可选，默认自动下载）
# OMNIPARSER_MODEL_PATH=/path/to/models

# ==================== 代理配置（如需）====================

# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890

# ==================== 项目说明 ====================
#
# 1. img2text2html2img 项目：
#    - 需要: VL_MODEL, LLM_MODEL
#    - API: 使用 --api-key 参数传入
#
# 2. ui_semantic_patch 项目：
#    - 必需: VLM_API_KEY, DASHSCOPE_API_KEY
#    - 可选: STRUCTURE_MODEL, VLM_MODEL, OMNIPARSER_DEVICE
#
