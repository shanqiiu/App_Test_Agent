---
marp: true
theme: default
paginate: true
backgroundColor: #fff
backgroundImage: url('https://marp.app/assets/hero-background.svg')
---

<!-- _class: lead -->
# 华为小艺Agent异常界面截图生成

## 基于深度生成模型的高保真方案

**项目状态**: Phase 1 - 调研与方案设计
**汇报日期**: 2026-01-08

---

## 目录

1. 研究背景与问题定义
2. 数据资源与目标
3. 技术方案：图像生成模型对比
4. 推荐方案：高保真图像编辑架构
5. 下一步工作计划

---

<!-- _class: lead -->
# 第一部分
## 研究背景与问题定义

---

## 研究背景

### 华为小艺Agent测试场景

**典型应用流程**:
```
用户指令 → 小艺理解 → 执行APP操作 → 获取结果 → 反馈用户
```

**测试挑战**:
- 🎯 需要覆盖大量**异常界面**场景
- 🎯 **实际异常样本极度稀缺**（真实环境难以触发）
- 🎯 传统测试环境无法模拟真实异常

---

## 核心问题

### 典型异常场景举例

> **电商购物场景**
> - 查询时：界面显示"商品有货"
> - 下单时：界面突然显示"商品缺货"
> - **状态不一致导致Agent决策错误**

**其他异常类型**:
- ❌ 支付失败（余额不足、网络超时）
- ❌ 权限缺失（未授权相机、位置）
- ❌ 数据异常（价格显示错误、库存为负）
- ❌ 网络波动（加载失败、超时重试）

---

## 问题定义

### 如何大规模生成高质量异常界面截图？

**输入资源**:
- ✅ GUIOdyssey数据集：大量**正常APP界面截图**
- ✅ 极少数**真实异常界面截图**（种子样本）

**目标输出**:
- 🎯 生成**足够数量**的异常界面截图
- 🎯 保证**高保真**：视觉质量接近真实截图
- 🎯 保证**风格一致**：与参考图片风格匹配


---

<!-- _class: lead -->
# 第二部分
## 数据资源与目标

---

## 核心数据资源

### GUIOdyssey数据集

**数据集概述**:
- 📦 包含**大规模移动APP界面截图**
- 📦 覆盖多种APP类型（电商、社交、工具等）
- 📦 **正常交互场景**为主

**使用价值**:
- ✅ 作为**风格参考**：学习真实APP界面风格
- ✅ 作为**编辑基础**：在正常截图上生成异常
- ✅ 提供**结构化信息**：UI元素布局、控件类型

---

## 种子样本：真实异常截图

### 极少数但价值极高

**样本特点**:
- 📸 数量极少（<10张典型样本）
- 📸 来自真实场景（实际测试中捕获）
- 📸 覆盖核心异常类型（缺货、支付失败等）

**作用**:
- 🎯 提供**异常模式参考**（错误提示样式、元素变化）
- 🎯 作为**生成目标**的质量标准
- 🎯 用于**Few-Shot学习**或Fine-tuning

---

## 技术目标与约束

### 高保真生成要求

| 维度 | 要求 | 评估方法 |
|------|------|---------|
| **视觉质量** | 照片级真实感 | LPIPS、FID、人工评分 |
| **风格一致性** | 与参考截图风格匹配 | CLIP相似度、颜色分布 |
| **语义合理性** | 符合真实异常逻辑 | 业务逻辑验证 |
| **元素完整性** | UI控件清晰可辨 | OCR准确率、控件检测 |

**关键挑战**:
- ⚠️ 少样本泛化（种子样本极少）
- ⚠️ 风格迁移（不同APP风格差异大）
- ⚠️ 细节保真（文字、图标必须清晰）

---

<!-- _class: lead -->
# 第三部分
## 技术方案：图像生成模型对比

---

## 技术方案分类

### 两大技术路线

**1️⃣ 文生图（Text-to-Image）**
- 从自然语言描述直接生成图像
- 代表：Stable Diffusion、DALL-E

**2️⃣ 图像编辑（Image-to-Image）**
- 基于参考图像进行局部修改
- 代表：InstructPix2Pix、ControlNet、Inpainting

**关键区别**:
- 文生图：更灵活，但难以精确控制细节
- 图像编辑：更可控，能保持原图风格和结构

---

## 方案一：纯文生图（Diffusion Models）

### 工作流程

```
文本描述: "淘宝APP商品缺货界面，显示红色错误提示"
    ↓
Stable Diffusion / DALL-E
    ↓
生成图像
```

**优势**:
- ✅ 生成多样性高
- ✅ 无需参考图像即可生成

**劣势**:
- ❌ **风格难以精确控制**（生成的APP风格可能偏差大）
- ❌ **UI元素准确性差**（按钮、文字可能模糊或错位）
- ❌ 需要大量训练数据

**适用性**: ⭐⭐ 不推荐（风格一致性无法保证）

---

## 方案二：LLM + Diffusion混合架构

### 工作流程

```
1. LLM生成详细描述
   输入: "商品缺货场景"
   输出: "显示红色文字'商品已售罄'，按钮变灰，添加库存提醒链接"

2. Diffusion生成图像
   基于描述 + ControlNet约束 → 生成异常界面
```

**优势**:
- ✅ LLM确保语义合理性
- ✅ ControlNet可保持布局结构

**劣势**:
- ❌ **仍难以保证风格完全一致**
- ❌ 推理速度慢（LLM + Diffusion双重开销）
- ❌ **无法精确控制UI元素细节**

**适用性**: ⭐⭐⭐ 中等（语义强但风格控制弱）

---

## 方案三：图像编辑模型（Image Inpainting）

### 工作流程

```
输入: 正常界面截图 (GUIOdyssey)
    ↓
局部编辑指令: "将'立即购买'按钮改为灰色'商品缺货'"
    ↓
Inpainting模型 (如Stable Diffusion Inpainting)
    ↓
输出: 异常界面截图
```

**优势**:
- ✅ **保持原图大部分区域不变**
- ✅ **风格自然一致**（基于真实截图）
- ✅ 可精确指定编辑区域

**劣势**:
- ⚠️ 需要精确的区域标注（mask）
- ⚠️ 大范围修改效果可能不佳

**适用性**: ⭐⭐⭐⭐ 推荐（风格一致性好）

---

## 方案四：指令式图像编辑（InstructPix2Pix）

### 工作流程

```
输入图像: 正常商品界面截图
    +
编辑指令: "将商品状态改为缺货，显示红色提示"
    ↓
InstructPix2Pix
    ↓
输出图像: 自动识别修改区域并生成异常界面
```

**优势**:
- ✅ **无需手动标注编辑区域**
- ✅ **保持原图风格和未修改区域**
- ✅ 自然语言指令，易用性强
- ✅ 推理速度快

**劣势**:
- ⚠️ 需要Fine-tune以适应APP界面风格
- ⚠️ 对复杂指令理解能力有限

**适用性**: ⭐⭐⭐⭐⭐ 强烈推荐（平衡易用性和质量）

---

## 方案五：Few-Shot图像编辑（Fine-tuned LoRA）

### 工作流程

```
1. 使用种子异常样本Fine-tune LoRA
   - 正常截图 + 异常截图配对
   - 学习异常变化模式

2. 推理阶段
   输入: 新的正常截图 + 异常类型
   输出: 对应的异常截图
```

**优势**:
- ✅ **充分利用少量种子样本**
- ✅ **风格高度一致**（学习真实异常样式）
- ✅ 泛化能力强
- ✅ 推理速度快

**劣势**:
- ⚠️ 需要准备配对训练数据
- ⚠️ 初期训练成本

**适用性**: ⭐⭐⭐⭐⭐ 强烈推荐（最适合少样本场景）

---

## 技术方案综合对比

| 方案 | 风格一致性 | 推理速度 | 易用性 | 少样本适应 | 推荐指数 |
|------|-----------|---------|--------|-----------|----------|
| 纯文生图 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐⭐ |
| LLM+Diffusion | ⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
| Inpainting | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
| InstructPix2Pix | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| LoRA Fine-tune | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |

**结论**: **InstructPix2Pix + LoRA Fine-tune** 组合方案最优

---

<!-- _class: lead -->
# 第四部分
## 推荐方案：高保真图像编辑架构

---

## 最优方案设计

### InstructPix2Pix + LoRA Fine-tune 混合架构

```
┌─────────────────────────────────────────────────┐
│          Phase 1: 数据准备与LoRA训练              │
│  GUIOdyssey正常截图 + 少量异常种子样本           │
│         ↓                                        │
│  LoRA Fine-tuning (学习APP风格 + 异常模式)       │
└─────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────┐
│          Phase 2: 推理生成                        │
│  输入: 正常截图 + 异常类型描述                    │
│         ↓                                        │
│  InstructPix2Pix + LoRA → 生成异常截图           │
└─────────────────────────────────────────────────┘
```

---

## 核心技术组件

### 1. InstructPix2Pix基座模型

**选择理由**:
- ✅ 原生支持自然语言指令编辑
- ✅ 无需手动标注编辑区域（自动识别变化区域）
- ✅ 保持原图未修改部分的风格和质量
- ✅ 推理速度快（单次前向传播）

**典型用法**:
```
image = load_image("淘宝商品详情页.png")
instruction = "将购买按钮改为灰色并显示'商品缺货'"
edited_image = model(image, instruction)
```

---

## 核心技术组件（续）

### 2. LoRA Fine-tuning策略

**训练数据构建**:
```
配对数据:
- 正常截图: GUIOdyssey数据集
- 异常截图: 手动注入异常元素（文字、按钮状态）
- 指令: "显示支付失败提示" / "商品缺货" 等
```

**LoRA优势**:
- ⚡ 训练参数少（<1%基座模型参数）
- ⚡ 训练速度快（小时级别）
- ⚡ 易于切换不同APP风格（多个LoRA模型）
- ⚡ 充分利用种子样本（Few-Shot学习）

---

## 核心技术组件（续）

### 3. 风格一致性保证机制

**多层次约束**:
```
1. CLIP风格匹配
   - 计算生成图与参考图的CLIP特征相似度
   - 阈值过滤低质量生成结果

2. 颜色分布约束
   - 保持APP主题色（色调、饱和度）
   - 避免生成风格偏差大的图像

3. 结构约束（可选）
   - ControlNet边缘检测保持布局
   - UI元素位置不发生大幅偏移
```

---

## 技术优势总结

### 为什么这个方案最适合？

| 要求维度 | 方案特性 | 优势 |
|---------|---------|------|
| **高保真** | 基于真实截图编辑 | 视觉质量天然接近真实 |
| **风格一致** | LoRA学习特定APP风格 | 生成结果与参考高度一致 |
| **少样本** | LoRA支持Few-Shot | 极少样本即可训练 |
| **易扩展** | 自然语言指令 | 新异常类型无需重新训练 |
| **高效率** | 推理速度快 | <5秒/张 |

---

## 实施路径

### 第一阶段：数据准备（1周）

**任务清单**:
1. ✅ 整理GUIOdyssey数据集（筛选高质量截图）
2. ✅ 收集种子异常样本（<10张核心异常类型）
3. ✅ 构建配对训练数据
   - 手动/半自动注入异常元素
   - 编写对应的编辑指令
   - 预计生成50-100对训练样本

**数据增强策略**:
- 使用传统图像编辑工具生成初始训练数据
- 利用LLM生成多样化的指令描述

---

## 实施路径（续）

### 第二阶段：模型训练（1-2周）

**LoRA训练配置**:
```python
基座模型: InstructPix2Pix
LoRA rank: 8-16
训练步数: 1000-3000
学习率: 1e-4
批次大小: 4-8
```

**训练策略**:
1. 先训练通用异常模式（跨APP）
2. 再Fine-tune特定APP风格（多个LoRA）

**验证指标**:
- CLIP相似度 > 0.85
- FID < 50
- 人工评分 > 4/5

---

## 实施路径（续）

### 第三阶段：测试与优化（1周）

**测试流程**:
```
1. 生成100张测试异常截图
2. 质量评估
   - 自动评估: LPIPS、FID、CLIP
   - 人工评估: 视觉质量、语义合理性
3. 迭代优化
   - 调整LoRA参数
   - 增加训练样本
   - 优化指令模板
```

**目标质量标准**:
- ✅ 视觉保真度: LPIPS > 0.85
- ✅ 风格一致性: CLIP相似度 > 0.85
- ✅ 人工评分: > 4.0/5.0
- ✅ 生成速度: < 5秒/张

---

## 风险与应对

### 主要技术风险

| 风险 | 影响 | 应对措施 |
|------|------|---------|
| 训练数据不足 | 中 | 数据增强 + 传统编辑工具辅助 |
| 风格泛化能力弱 | 中 | 多LoRA策略 + 增加训练样本多样性 |
| UI元素细节模糊 | 高 | 后处理锐化 + 超分辨率 |
| 语义不合理 | 低 | LLM生成指令 + 规则约束 |

**降低风险措施**:
- 分阶段验证，及时调整方案
- 建立质量评估流水线，快速迭代
- 保留备选方案（Inpainting）

---

## 预期成果

### 技术指标

- 📊 生成异常截图数量: **500+ 张**
- 📊 覆盖异常类型: **10+ 类型**
- 📊 视觉保真度: **LPIPS > 0.85**
- 📊 生成速度: **< 5秒/张**
- 📊 人工质量评分: **> 4.0/5.0**

### 业务价值

- 🎯 测试覆盖率提升: **50%+**
- 🎯 异常样本获取成本降低: **80%+**
- 🎯 测试场景生成效率: **10倍提升**
---

<!-- _class: lead -->
# 第五部分
## 下一步工作计划

---

## 近期计划（4周内）

### Week 1: 数据准备与环境搭建

**核心任务**:
- [ ] 获取并整理GUIOdyssey数据集
- [ ] 收集华为小艺测试中的种子异常样本
- [ ] 搭建InstructPix2Pix开发环境
- [ ] 构建50-100对配对训练数据

**关键产出**:
- 清洗后的GUIOdyssey数据集（1000+张高质量截图）
- 种子异常样本库（5-10张典型异常）
- 训练数据集（50-100对）

---

## 近期计划（续）

### Week 2-3: LoRA模型训练

**训练流程**:
```
1. 基线测试（无Fine-tune）
   - 使用原始InstructPix2Pix测试效果
   - 识别主要问题（风格偏差、细节丢失等）

2. LoRA训练
   - 配置LoRA参数（rank=8-16）
   - 训练1000-3000步
   - 验证集测试

3. 超参数调优
   - 学习率、批次大小、训练步数
   - 选择最优配置
```

**关键产出**:
- 训练好的LoRA模型权重
- 训练日志和评估报告

---

## 近期计划（续）

### Week 4: 测试与评估

**测试流程**:
```
1. 定量评估
   - 生成100张测试图像
   - 计算LPIPS、FID、CLIP指标
   - 统计生成速度

2. 定性评估
   - 人工打分（5分制）
   - 风格一致性评估
   - 语义合理性检查

3. 结果分析
   - 识别失败案例
   - 分析改进方向
```

**关键产出**:
- 测试报告（含量化指标）
- 生成样本展示（best/worst cases）
- 优化建议清单

---

## 中期规划（2-3个月）

### 扩展与优化

**阶段目标**:
1. 扩展异常类型覆盖
   - 从5类扩展到10+类异常
   - 覆盖"衣食住行"高频场景

2. 提升生成质量
   - 引入超分辨率后处理
   - 优化文字清晰度
   - 改进颜色匹配

3. 建立评估基准
   - 构建标准测试集
   - 建立自动化评估流水线

---

## 中期规划（续）

### 多APP适配

**策略**:
```
训练多个LoRA模型，每个专门适配一类APP:
- LoRA_电商 (淘宝、京东、拼多多)
- LoRA_支付 (微信支付、支付宝)
- LoRA_出行 (高德、滴滴)
- LoRA_社交 (微信、QQ)
```

**优势**:
- 风格更精准
- 切换灵活
- 训练成本低

---

## 资源需求

### 硬件资源

| 资源类型 | 规格 | 用途 |
|---------|------|------|
| GPU | NVIDIA A100 / V100 | 模型训练（1-2周） |
| GPU | NVIDIA RTX 4090 | 推理生成（长期） |
| 存储 | 500GB SSD | 数据集和模型存储 |

### 软件资源

- PyTorch 2.0+
- Diffusers库（Hugging Face）
- InstructPix2Pix预训练模型
- LoRA训练工具（PEFT库）

---

## 资源需求（续）

### 人力投入

**核心团队**:
- 算法工程师（1人）：模型训练与优化
- 数据工程师（0.5人）：数据准备与标注
- 测试工程师（0.5人）：质量评估与验证

**预计工作量**:
- Phase 1（4周）：2人月
- Phase 2（2-3个月）：4-6人月

---

## 成功标准

### 短期目标（4周）

- ✅ 完成LoRA模型训练
- ✅ 生成100张测试样本
- ✅ 视觉保真度: LPIPS > 0.80
- ✅ 人工评分: > 3.5/5.0

### 中期目标（3个月）

- ✅ 生成500+张异常截图
- ✅ 覆盖10+异常类型
- ✅ 视觉保真度: LPIPS > 0.85
- ✅ 人工评分: > 4.0/5.0
- ✅ 测试覆盖率提升50%+

---

<!-- _class: lead -->
# 总结

---

## 核心亮点

### 🎯 问题精准定位
- 聚焦华为小艺Agent异常界面测试
- 明确数据资源（GUIOdyssey + 种子样本）
- 清晰的技术目标（高保真、风格一致）

### 🚀 技术方案创新
- InstructPix2Pix + LoRA混合架构
- 充分利用极少样本（Few-Shot学习）
- 平衡质量、效率、成本

---

## 核心亮点（续）

### 📊 可量化的价值
- 测试覆盖率提升50%+
- 异常样本获取成本降低80%+
- 生成效率10倍提升

### 💡 清晰的实施路径
- 4周短期计划（PoC验证）
- 2-3个月中期规划（规模化）
- 分阶段里程碑明确

---

## 关键优势

### 为什么选择图像编辑而非文生图？

| 对比维度 | 文生图 | 图像编辑（我们的方案） |
|---------|--------|---------------------|
| 风格一致性 | ❌ 难控制 | ✅ 基于真实截图 |
| UI元素准确性 | ❌ 易模糊 | ✅ 保持原图质量 |
| 训练数据需求 | ❌ 大量数据 | ✅ 少量样本即可 |
| 推理速度 | ⚠️ 中等 | ✅ 快速 |

**结论**: 图像编辑天然适合异常界面生成场景

---

## 技术创新点

### 1. 少样本异常生成
- LoRA充分利用<10张种子样本
- 数据增强策略降低标注成本

### 2. 风格迁移学习
- 多LoRA策略适配不同APP
- CLIP约束保证风格一致性

### 3. 高保真保证
- 基于真实截图编辑
- 多层次质量约束机制

---

## 下一步行动

### 立即启动

1. **数据准备**（本周开始）
   - 获取GUIOdyssey数据集
   - 收集种子异常样本

2. **环境搭建**（下周完成）
   - 申请GPU资源
   - 安装InstructPix2Pix环境

3. **PoC验证**（4周内）
   - 完成首个LoRA模型训练
   - 验证技术可行性

---

<!-- _class: lead -->
# 谢谢！

## Q & A

**项目仓库**: d:\my_git_projects\App_Test_Agent
**联系方式**: 欢迎讨论与交流

---

## 附录：参考资源

### 核心数据集
- **GUIOdyssey**: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices
  - 大规模移动APP界面截图数据集
  - 覆盖多种APP类型和交互场景

---

## 附录：核心技术

### InstructPix2Pix
- **论文**: InstructPix2Pix: Learning to Follow Image Editing Instructions
- **优势**: 自然语言指令驱动的图像编辑
- **代码**: https://github.com/timothybrooks/instruct-pix2pix

### LoRA (Low-Rank Adaptation)
- **论文**: LoRA: Low-Rank Adaptation of Large Language Models
- **优势**: 高效参数微调，训练成本低
- **适用**: 少样本场景的快速适配

---

## 附录：技术栈

### 核心框架
```
深度学习框架
├── PyTorch 2.0+
├── Diffusers (Hugging Face)
└── PEFT (Parameter-Efficient Fine-Tuning)

图像处理
├── OpenCV
├── Pillow
└── Albumentations

评估工具
├── LPIPS (感知相似度)
├── FID (图像质量)
└── CLIP (风格匹配)
```

---

## 附录：相关研究

### 学术研究
- **UI生成**: UI-UG: A Unified MLLM for UI Understanding and Generation
- **风格一致性**: OmniConsistency: Learning Style-Agnostic Consistency
- **图像编辑**: Automated UI Interface Generation via Diffusion Models

### 业界实践
- 目前无直接竞品（UI异常生成是新领域）
- 相关工作主要集中在UI设计自动化（正常界面）

---

## 附录：关键指标说明

### LPIPS (Learned Perceptual Image Patch Similarity)
- **用途**: 衡量图像感知相似度
- **范围**: 0-1，值越高越相似
- **目标**: > 0.85（高度相似）

### FID (Fréchet Inception Distance)
- **用途**: 衡量生成图像质量
- **范围**: 0-∞，值越低越好
- **目标**: < 50（高质量）

### CLIP Similarity
- **用途**: 衡量风格一致性
- **范围**: 0-1，值越高风格越一致
- **目标**: > 0.85

---

## 附录：联系与讨论

### 获取更多信息
- 📂 完整文档：[项目根目录](.)
- 📚 调研文档：[docs/research/](docs/research/)
- 🗺️ 研究规划：[docs/planning/](docs/planning/)
- 📖 技术文档：[docs/technical/](docs/technical/)

### 技术交流
- 欢迎提供异常样本
- 欢迎讨论技术方案
- 欢迎贡献数据标注
