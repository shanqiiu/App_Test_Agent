# 模型选型与工程实施方案

**文档类型**: 技术调研
**创建日期**: 2026-01-08
**标签**: `模型选型` `工程实施` `Diffusion Models` `LoRA微调`

---

## 背景与需求

### 业务场景

利用小艺Agent进行手机App操作时，会出现执行异常问题。原因在于手机App各种异常情况的出现：
- **订票App**: 余票为0导致无法继续
- **美团**: 广告遮挡操作按钮，Agent无法执行下一步
- **支付场景**: 余额不足、网络超时等

### 核心挑战

**数据现状**: 大量正常App界面截图 + 极少量异常界面截图

**技术目标**:
- 生成高保真、多样化的异常界面图像
- 用于Agent训练和测试，提升鲁棒性

---

## 需求分析与技术挑战

### 核心需求

1. **数据稀缺性**: 异常样本极少，需模型具备**少样本泛化**能力
2. **高保真度**: 生成图像需高度还原真实App UI风格、布局、文字渲染
3. **精准控制**: 能精确控制异常元素（特定文字、遮挡位置）的出现
4. **工程可行性**: 模型需能在RTX 4090等消费级显卡上微调和推理

### 关键技术要求

| 技术维度 | 具体要求 | 重要性 |
|---------|---------|--------|
| 少样本泛化 | 基于少量异常样本生成多样化变体 | 🔥 高 |
| 风格保真 | 精确还原App UI风格、配色、字体 | 🔥 高 |
| 可控生成 | 支持精确的异常元素控制 | 🔥 高 |
| 硬件适配 | 16GB显存可训练和推理 | 🔥 高 |
| 开源可控 | 模型开源，支持本地微调 | ⭐ 中 |

---

## 候选模型技术评估

### 模型对比矩阵

| 模型 | 参数量 | 开源 | 编辑能力 | 微调友好度 | 4090适配 | 综合评价 |
|------|--------|------|---------|-----------|---------|---------|
| **Z-Image Turbo** | **6B** | ✅ 是 | Z-Image-Edit已开源 | ⭐⭐⭐⭐⭐ 极高 | ✅ 完美 (16GB) | ⭐⭐⭐⭐⭐ **首选** |
| **Flux 12B** | 12B | ✅ 是 | 原生支持 | ⭐⭐⭐⭐ 高 (需QLoRA) | ⚠️ 需4bit量化 | ⭐⭐⭐⭐ 备选 |
| **Qwen-Image** | ~20B+ | ✅ 是 | ✅ 强 | ⭐⭐ 低 (太大) | ❌ 困难 | ⭐⭐ 不推荐 |
| **混元(Hunyuan)** | ~80B | ❌ 否 | 未知 | ❌ 无法微调 | ❌ 无法本地部署 | ❌ 不适用 |

---

## 推荐方案：Z-Image Turbo

### 核心优势

#### 1. 轻量高效 ⭐⭐⭐⭐⭐

**性能表现**:
- 仅6B参数，在权威评测中**超越32B的Flux 2和Qwen-Image**
- 成为当前最强开源文生图模型

**硬件要求**:
- Turbo版本专为消费级硬件优化
- **16GB显存即可流畅运行**
- 推理速度极快（**1秒出图**）

#### 2. 完善的编辑能力 ⭐⭐⭐⭐⭐

**Z-Image-Edit**:
- 官方发布的图像编辑衍生模型
- 专为图像编辑任务优化
- **卓越的指令跟随能力**

**应用示例**:
```
输入指令: "在按钮上添加一个广告横幅"
模型能力: 精准响应，准确定位和生成
```

#### 3. 微调成本低 ⭐⭐⭐⭐⭐

**LoRA微调优势**:
- 轻量化基座模型（仅6B）
- LoRA微调成本极低
- 非常适合垂直领域（App界面）定制化

**资源需求**:
- 单卡RTX 4090即可完成
- 训练时间: 1-2天/APP
- 存储成本: ~100MB/LoRA模型

---

## 备选方案：Flux 12B (量化版)

### 技术方案

#### SVDQuant量化技术

**技术来源**: MIT Han实验室

**量化效果**:
- **4bit量化**成功实现
- 可在**16GB RTX 4090**上运行
- 内存占用减少**3.5倍**
- 推理延迟降低**8.7倍**

#### Lvmin Zhang的GGUF量化

**技术特点**:
- 将Flux.1-dev量化为GGUF格式
- 支持INT4、INT5、INT8等多种低比特量化
- 公开发布在Hugging Face: `lllyasviel/FLUX.1-dev-gguf`

**重要说明**:
- GGUF主要用于**推理加速**
- LoRA微调仍需在原始FP16模型上进行
- 或使用QLoRA技术（bitsandbytes库）进行4-bit微调

### 适用场景

✅ **作为性能补充**:
- Z-Image在极小字号、复杂图标上表现不足时
- 需要更强大的生成能力时

✅ **高质量要求**:
- 追求极致的生成质量
- 不敏感推理延迟（量化后仍快于原版）

---

## 排除方案分析

### Qwen-Image: 参数量过大

**排除原因**:
- 参数量20B+，微调成本过高
- 推理资源需求大
- 不符合"轻量级"和"4090可训"的核心要求

**技术评估**:
- 虽然能力强，但工程成本不可接受
- 不适合快速迭代和实验

### 混元(Hunyuan): 未开源

**排除原因**:
- ❌ 未开源，无法本地微调
- ❌ 无法进行编辑能力的二次开发
- ❌ 不支持定制化风格适配

**结论**: 完全不适合此业务场景

---

## 具体实施方案 🎯

### 技术架构

```
基座模型: Z-Image Turbo (6B)
    ↓
两阶段LoRA微调
    ↓
推理与质量控制
```

### 第一阶段：风格对齐

**训练目标**: 使模型完美掌握目标App的UI风格

**训练数据**:
- 使用**大量正常App截图**（1k-5k张/APP）
- 覆盖各种界面状态和交互场景

**训练方法**:
- **LoRA微调** Z-Image Turbo
- 学习APP特定的：
  - UI风格和配色方案
  - 字体、字号、字重规范
  - 布局结构和间距规则
  - 控件样式（按钮、输入框、弹窗等）

**预期产出**:
- APP风格适配器（LoRA权重）
- 能够生成高度一致的APP界面

---

### 第二阶段：异常注入

**训练目标**: 教会模型如何生成特定异常元素

**训练数据**:
- 使用**极少量异常截图**（100-200张）
- 标注异常类型和位置信息

**训练方法**:
- 在风格对齐模型基础上进行**第二轮LoRA微调**
- 学习如何：
  - 在正确位置生成异常元素
  - 以正确样式呈现异常状态
  - 保持整体界面的协调性

**异常类型覆盖**:
- **控件类**: 点击无响应、按钮变灰
- **页面显示类**: 弹窗广告、布局错位、加载失败
- **页面内容类**: 商品缺货、余额不足、余票为0

---

### 生成与控制

#### 指令式生成

**利用Z-Image-Edit的指令跟随能力**:

```python
# 示例指令
prompt = """
在[美团外卖]的主界面上，
在[商家列表区域]添加一个全屏广告遮罩，
广告内容为'限时优惠'，
遮挡住底部的[立即下单]按钮
"""
```

**精确控制要素**:
- APP名称和界面类型
- 异常位置（具体坐标区域）
- 异常内容和样式
- 影响范围和程度

#### 布局一致性保证

**技术方案**:

1. **ControlNet约束**:
   - 以正常截图作为参考图
   - 提取布局结构（Canny边缘、深度图）
   - 确保生成图像的布局一致性

2. **IP-Adapter融合**:
   - 保留原始界面的视觉风格
   - 仅修改异常相关区域
   - 实现精确的局部编辑

---

### 工程部署架构

```
数据收集
    ↓
LoRA微调 (单卡4090)
    ├── 阶段1: 风格对齐 (1-2天)
    └── 阶段2: 异常注入 (1-2天)
    ↓
推理生成 (单卡4090)
    ├── 批量预生成 (离线)
    └── 实时生成 (在线)
    ↓
质量验证
    ├── 自动化指标 (CLIP相似度、FID)
    └── 人工抽检
```

**资源需求**:
- 硬件: 1-2张 RTX 4090
- 存储: ~500GB (数据 + 模型)
- 时间: 1周/APP (数据收集 + 微调 + 验证)

**成本优势**:
- ✅ 无需昂贵的计算集群
- ✅ 符合轻量级和成本效益要求
- ✅ 支持快速迭代和实验

---

## 质量保证机制

### 自动化评估

| 指标 | 度量内容 | 目标值 |
|------|---------|--------|
| CLIP相似度 | 风格一致性 | > 0.85 |
| FID分数 | 视觉保真度 | < 50 |
| LPIPS | 感知质量 | < 0.2 |

### 人工验证

**评估维度**:
- ✅ 异常元素是否准确生成
- ✅ 界面风格是否一致
- ✅ 语义是否合理
- ✅ 是否存在明显伪影

**验证流程**:
1. 生成异常截图
2. 测试工程师评分（1-5分）
3. 不合格样本重新生成
4. 建立高质量样本库

---

## 风险评估与应对

### 技术风险

#### 1. 生成质量不稳定

**风险描述**:
- Z-Image可能在某些极端场景表现不佳
- 极小字号文字可能模糊
- 复杂图标可能失真

**应对措施**:
- 建立多层质量筛选机制
- 使用CLIP自动评分和过滤
- 对低质量样本启用Flux备选方案
- 保留生成参数支持重现和调优

#### 2. 数据依赖

**风险描述**:
- 需要收集足够的正常截图（1k-5k张/APP）
- 异常截图收集困难

**应对措施**:
- 建立自动化截图采集工具
- 利用UI遍历技术批量采集
- 与业务团队合作收集真实异常案例
- 使用数据增强扩充样本

### 工程风险

#### 1. 微调成本

**风险描述**:
- 每个APP需要单独微调
- 多APP场景成本累积

**应对措施**:
- 建立通用风格适配器
- 跨APP知识迁移
- 优先覆盖TOP 10高频APP
- 建立微调自动化pipeline

#### 2. 模型维护

**风险描述**:
- APP界面更新后模型失效
- 需要定期重新微调

**应对措施**:
- 建立版本管理机制
- 监控APP更新，触发增量训练
- 保留历史版本的LoRA权重
- 建立A/B测试验证新模型质量

---

## 实施时间线

### Phase 1: 技术验证（2周）

**目标**: 验证技术可行性

- [ ] 搭建Z-Image Turbo推理环境
- [ ] 在单个APP（如美团）上测试生成效果
- [ ] 收集500-1000张正常截图
- [ ] 完成第一轮LoRA微调
- [ ] 生成10-20个异常场景样本
- [ ] 建立初步评估指标

### Phase 2: MVP开发（4周）

**目标**: 打通完整流程

- [ ] 扩展至3个APP（美团、携程、淘宝）
- [ ] 完成两阶段LoRA微调pipeline
- [ ] 建立自动化质量评估系统
- [ ] 生成50+异常场景
- [ ] 在Agent测试中验证效果
- [ ] 完成Flux备选方案集成

### Phase 3: 规模化部署（8周）

**目标**: 覆盖主要场景

- [ ] 扩展至10个TOP APP
- [ ] 建立异常场景库（500+场景）
- [ ] 优化微调和推理效率
- [ ] 建立持续更新机制
- [ ] 形成标准化工具和文档

---

## 成功标准

### 技术指标

- ✅ 视觉保真度: CLIP相似度 > 0.85
- ✅ 生成速度: < 2秒/张（批量）
- ✅ 异常覆盖率: 50+异常场景类型
- ✅ 模型大小: 单个LoRA < 200MB

### 业务指标

- ✅ Agent异常处理成功率提升 > 30%
- ✅ Corner Case发现率提高 > 35%
- ✅ 测试成本降低 > 40%

---

## 结论与建议

### 核心结论

**强烈推荐采用 Z-Image Turbo 作为核心模型** ⭐⭐⭐⭐⭐

**理由**:
1. ✅ 完美契合所有关键技术要求
2. ✅ 开源、可编辑、微调成本低
3. ✅ 4090完美适配，工程可行性高
4. ✅ 性能优异，超越更大参数量模型

**备选方案**:
- Flux 12B（量化版）作为性能兜底
- 用于Z-Image处理不佳的特殊场景

### 实施建议

1. **立即启动**: 技术路线清晰，可立即开始验证
2. **小步快跑**: 先单APP验证，再逐步扩展
3. **质量优先**: 建立严格的质量评估机制
4. **持续优化**: 基于实际效果迭代改进

---

## 相关文档

- [方案可行性分析](./01_方案可行性分析.md) - 整体方案评估
- [程序化异常生成调研](./02_程序化异常生成调研.md) - 生成方法论
- [异常界面生成技术路线分析](./03_异常界面生成技术路线分析.md) - 技术路线对比
- [技术栈与工具](../technical/技术栈与工具.md) - 相关技术说明
- [研究路线图](../planning/研究路线图.md) - 整体研究规划

---

## 附录：技术术语

### Z-Image
- 开源文生图模型，仅6B参数
- 性能超越Flux 2、Qwen-Image
- 官方提供编辑版本（Z-Image-Edit）

### LoRA (Low-Rank Adaptation)
- 参数高效微调技术
- 仅训练少量参数（通常<1%）
- 适合资源受限的垂直领域微调

### ControlNet
- 控制扩散模型生成的技术
- 支持边缘、深度、姿态等多种控制条件
- 确保生成图像的结构一致性

### GGUF量化
- llama.cpp推广的模型量化格式
- 支持INT4、INT5、INT8等低比特量化
- 大幅降低显存占用和推理延迟

---

**创建日期**: 2026-01-08
**基于**: 实际技术调研与模型评估
**核心贡献**: 明确工程化实施路径，推荐Z-Image Turbo作为最优方案