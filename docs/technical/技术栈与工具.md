# 技术栈与工具

本文档记录AI智能体异常测试场景生成项目中使用的核心技术栈、工具和框架。

**文档类型**: 技术文档
**最后更新**: 2026-01-08
**基于**: [模型选型与工程实施方案](../research/04_模型选型与工程实施方案.md)

---

## 核心生成模型

### 🌟 Z-Image Turbo（首选方案）

**基本信息**:
- **参数量**: 6B
- **开源状态**: ✅ 完全开源
- **官方地址**: Hugging Face Model Hub
- **推荐理由**: 轻量高效、编辑能力强、微调成本低

**技术特点**:
- 性能超越32B的Flux 2和Qwen-Image
- 当前最强开源文生图模型
- 专为消费级硬件优化（16GB显存即可）
- 推理速度极快（约1秒/图）

**应用场景**:
- App异常界面图像生成
- UI风格对齐和迁移
- 指令式精确编辑

**硬件要求**:
- 推理: RTX 4090 (16GB显存)
- 微调: RTX 4090 (16GB显存) + LoRA

---

### Z-Image-Edit（图像编辑专用）

**基本信息**:
- **类型**: Z-Image的编辑特化版本
- **开源状态**: ✅ 官方开源
- **核心优势**: 卓越的指令跟随能力

**技术能力**:
- 精准的区域编辑控制
- 支持自然语言指令引导
- 保持原始风格的局部修改

**应用示例**:
```python
# 指令式异常注入
prompt = """
在[美团外卖]的主界面上，
在[商家列表区域]添加一个全屏广告遮罩，
广告内容为'限时优惠'，
遮挡住底部的[立即下单]按钮
"""
# 模型能精准响应，生成符合要求的异常界面
```

**应用场景**:
- 异常元素注入
- 界面遮挡生成
- 特定区域修改

---

### Flux 12B（备选方案）

**基本信息**:
- **参数量**: 12B
- **开源状态**: ✅ 开源（Flux.1-dev）
- **推荐场景**: Z-Image处理不佳的特殊场景

**量化方案**:

#### 1. SVDQuant（MIT Han实验室）
- **量化精度**: 4-bit
- **内存优化**: 减少3.5倍
- **推理加速**: 降低8.7倍延迟
- **硬件适配**: 16GB RTX 4090可运行

#### 2. GGUF量化（Lvmin Zhang）
- **模型地址**: `lllyasviel/FLUX.1-dev-gguf`
- **支持精度**: INT4、INT5、INT8
- **主要用途**: 推理加速
- **注意事项**: 微调仍需在FP16模型上进行

**适用场景**:
- 极小字号文字渲染
- 复杂图标精确生成
- 对质量要求极高的场景
- Z-Image表现不足时的兜底

**硬件要求**:
- 推理: RTX 4090 + 4-bit量化
- 微调: QLoRA（4-bit微调）

---

## 图像编辑模型

### InstructPix2Pix

**基本信息**:
- **类型**: 指令式图像编辑模型
- **开源状态**: ✅ 开源
- **核心功能**: 根据自然语言指令编辑图像

**技术特点**:
- 支持自然语言编辑指令
- 保持图像主体结构不变
- 精确的局部修改能力

**在项目中的应用**:
```python
# 示例：修改按钮状态
instruction = "Change the button to disabled state and show 'Out of Stock'"
edited_image = instruct_pix2pix(
    image=original_screenshot,
    instruction=instruction
)
```

**应用场景**:
- 状态标签修改
- 按钮状态变更
- 文本内容替换

---

### ControlNet Inpainting

**基本信息**:
- **类型**: 基于ControlNet的图像修复模型
- **核心功能**: 精确控制局部区域修改

**技术特点**:
- Mask区域精确控制
- 保持边界自然过渡
- 支持多层编辑

**在项目中的应用**:
- 异常元素精确注入
- 弹窗/Toast叠加
- 图片加载失败区域生成

**优势**:
- ✅ 精确的区域控制
- ✅ 自然的边界融合
- ✅ 支持复杂编辑

---

## 风格迁移技术

### AdaIN (Adaptive Instance Normalization)

**核心原理**:
- 自适应实例归一化
- 实时风格迁移技术
- 保持内容结构的风格转换

**技术特点**:
- 快速（实时处理）
- 风格迁移质量高
- 适合移动UI风格对齐

**在项目中的应用**:
```python
# 风格对齐流程
content = generated_anomaly_image  # 生成的粗糙异常界面
style = reference_app_screenshot   # 参考应用截图

# AdaIN风格迁移
aligned_image = adain_style_transfer(content, style)
```

**应用场景**:
- 跨应用风格对齐
- 生成图像风格修正
- 实时风格迁移

---

### NST (Neural Style Transfer)

**核心原理**:
- 基于CNN的风格迁移
- 高质量风格对齐
- 计算成本较高

**技术特点**:
- 质量优于AdaIN
- 需要优化迭代
- 适合离线处理

**在项目中的应用**:
- 高质量风格对齐
- 最终生成图像精修
- 批量风格统一处理

---

### ILVR (Iterative Latent Variable Refinement)

**核心原理**:
- 迭代潜空间变量精炼
- 保持内容的风格迁移
- 基于扩散模型

**技术特点**:
- 扩散模型原生支持
- 内容保持能力强
- 风格迁移精确

**在项目中的应用**:
- 保持异常元素内容的风格迁移
- 精确的风格控制
- 多阶段风格优化

---

## UI理解与布局技术

### LayoutLM/LayoutNet

**核心功能**:
- 学习UI界面布局模式
- 理解界面元素层级关系

**在项目中的应用**:
- 界面布局约束
- 异常元素位置合理性判断
- 生成布局验证

**技术优势**:
- ✅ 理解界面语义
- ✅ 保证布局合理性
- ✅ 支持多种界面类型

---

### Semantic Segmentation

**核心功能**:
- 界面区域语义分割
- UI元素识别与分类

**在项目中的应用**:
```python
# 识别界面区域
segments = segment_ui(screenshot)
# segments: {
#   'title_bar': [0, 0, 1080, 180],
#   'content': [0, 180, 1080, 2100],
#   'button': [50, 2100, 1030, 2280]
# }

# 在特定区域注入异常
inject_anomaly(screenshot, region=segments['button'])
```

**应用场景**:
- 精确定位修改区域
- 界面元素分类
- 异常注入位置选择

---

## 少样本学习技术

### DreamBooth

**核心原理**:
- 个性化扩散模型微调
- Few-Shot学习
- 特殊token绑定概念

**在项目中的应用**:
```python
# 使用少量真实异常学习异常模式
anomaly_samples = load_real_anomalies(num=10)  # 仅10张

# DreamBooth微调
model = dreambooth_finetune(
    base_model="z-image-turbo",
    instance_images=anomaly_samples,
    instance_prompt="A mobile app screenshot with [OOS] error",
    num_epochs=100
)
```

**应用场景**:
- 学习特定异常模式（缺货、网络错误等）
- 少量真实异常样本增强
- 快速适应新异常类型

**优势**:
- ✅ 仅需10-20张样本
- ✅ 学习效果好
- ✅ 训练成本低

---

### Textual Inversion

**核心原理**:
- 学习特定概念的embedding
- 通过文本token表示视觉概念

**在项目中的应用**:
- 学习特定应用的风格token
- 学习异常元素的视觉表示
- 快速风格切换

**技术特点**:
- 仅学习embedding（极小参数）
- 可组合多个token
- 训练速度快

---

## 图像质量增强

### Real-ESRGAN

**核心功能**:
- 真实世界图像超分辨率
- 提升图像清晰度

**在项目中的应用**:
```python
# 生成后超分辨率处理
low_res_image = generate_anomaly_screenshot(...)  # 512x1024
high_res_image = real_esrgan.enhance(
    low_res_image,
    scale=2  # 输出1024x2048
)
```

**应用场景**:
- 提升生成图像分辨率
- 文字清晰度增强
- 图标锐化

**优势**:
- ✅ 真实感强
- ✅ 文字处理好
- ✅ 适合UI截图

---

### SwinIR

**核心功能**:
- 基于Transformer的图像恢复
- 超分辨率、去噪

**技术特点**:
- Swin Transformer架构
- 长距离依赖建模
- 质量优秀

**在项目中的应用**:
- 高质量超分辨率
- 图像去噪处理
- 细节增强

---

## OCR与文本处理

### PaddleOCR

**核心功能**:
- 高性能OCR识别
- 支持中英文

**在项目中的应用**:
```python
# 质量检查：验证文本准确性
generated_text = paddle_ocr(generated_image)
target_text = "商品缺货"

if generated_text != target_text:
    # 文本修正或重新生成
    corrected_image = correct_text(generated_image, target_text)
```

**应用场景**:
- 生成图像文本验证
- 质量检查
- 异常描述准确性评估

**优势**:
- ✅ 中文识别准确
- ✅ 速度快
- ✅ 开源免费

---

### 文本区域修正

**技术方案**:
- OCR识别 + 文本重渲染
- 确保文本清晰准确

**实现流程**:
```python
# 1. OCR识别文本区域
text_regions = detect_text_regions(image)

# 2. 重新渲染文本
for region in text_regions:
    if region.confidence < 0.9:
        # 使用原生字体重新渲染
        render_text(image, region, clear_font=True)
```

---

## 微调与优化技术

### LoRA (Low-Rank Adaptation)

**核心原理**:
- 参数高效微调技术
- 仅训练少量参数（通常<1%）
- 保持基座模型不变

**技术优势**:
- ✅ 微调成本极低（单卡4090即可）
- ✅ 存储成本低（~100MB/LoRA模型）
- ✅ 支持多个LoRA并行管理
- ✅ 适合垂直领域定制化

**在项目中的应用**:

#### 阶段1: 风格对齐LoRA
- **训练数据**: 1k-5k张正常App截图
- **训练时间**: 1-2天/APP
- **学习目标**: UI风格、配色、字体、布局

#### 阶段2: 异常注入LoRA
- **训练数据**: 100-200张异常截图
- **训练时间**: 1-2天
- **学习目标**: 异常元素生成、位置控制

**技术栈**:
- PyTorch
- Hugging Face PEFT库
- Diffusers库

---

### QLoRA (Quantized LoRA)

**核心技术**:
- 4-bit量化 + LoRA微调
- 进一步降低显存需求
- 适用于大参数模型（如Flux 12B）

**技术实现**:
- **依赖库**: bitsandbytes
- **量化精度**: 4-bit NF4格式
- **显存优化**: 约50%显存占用

**应用场景**:
- Flux 12B的微调
- 显存受限环境
- 多模型并行训练

---

## 生成控制技术

### ControlNet

**核心功能**:
- 控制扩散模型的生成过程
- 保证生成图像的结构一致性

**控制条件类型**:
- **Canny边缘**: 提取布局边界
- **深度图**: 保持空间结构
- **姿态**: 控制元素位置（如有）

**在项目中的应用**:
```python
# 布局一致性保证
1. 以正常截图作为参考图
2. 提取布局结构（Canny边缘）
3. 生成时约束布局不变
4. 仅修改异常相关区域
```

**技术优势**:
- ✅ 精确的布局控制
- ✅ 防止生成布局偏移
- ✅ 保持UI结构一致性

---

### IP-Adapter

**核心功能**:
- 图像提示适配器
- 保留原始风格的局部编辑

**技术原理**:
- 提取参考图像的视觉特征
- 将特征注入生成过程
- 实现风格保持的编辑

**在项目中的应用**:
- 保留App原始视觉风格
- 仅修改异常元素
- 精确的局部编辑控制

**优势**:
- ✅ 风格一致性强
- ✅ 支持精细控制
- ✅ 减少生成伪影

---

## 模型量化技术

### SVDQuant

**技术来源**: MIT Han实验室

**核心技术**:
- 基于SVD的量化方法
- 针对扩散模型优化

**量化效果**（Flux 12B）:
- **精度**: 4-bit
- **内存**: 减少3.5倍
- **速度**: 推理延迟降低8.7倍
- **质量**: 最小化精度损失

**适用模型**:
- Flux系列
- 其他大型扩散模型

---

### GGUF量化

**技术特点**:
- llama.cpp生态的量化格式
- 支持多种低比特精度

**支持精度**:
- INT4
- INT5
- INT8

**重要说明**:
- ⚠️ 主要用于推理加速
- ⚠️ LoRA微调仍需FP16模型
- ⚠️ 或配合QLoRA进行4-bit微调

**Flux.1-dev GGUF**:
- **模型地址**: `lllyasviel/FLUX.1-dev-gguf`
- **公开平台**: Hugging Face
- **支持工具**: llama.cpp兼容工具链

---

### SSIM (Structural Similarity Index)

**应用场景**:
- 结构相似度评估
- 布局一致性检查

**评估指标**:
- **SSIM分数**: 0-1之间，越高越相似
- **目标值**: > 0.7

**技术原理**:
- 基于亮度、对比度、结构三个维度
- 更符合人类视觉感知
- 局部区域比较

**应用示例**:
```python
from skimage.metrics import structural_similarity as ssim

# 计算生成图像与参考图像的结构相似度
score = ssim(generated_img, reference_img, multichannel=True)
```

**优势**:
- ✅ 结构保持度量
- ✅ 适合评估编辑质量
- ✅ 计算快速

---

### Style Loss (Gram矩阵距离)

**应用场景**:
- 风格一致性精确评估
- 风格迁移质量度量

**评估指标**:
- **Style Loss**: 越低风格越一致
- **目标值**: < 0.2

**技术原理**:
- 使用VGG网络提取风格特征
- 计算Gram矩阵捕捉纹理信息
- 比较参考图像与生成图像的风格差异

**应用示例**:
```python
def compute_style_loss(generated_img, reference_img):
    # 提取VGG特征
    gen_features = vgg_extractor(generated_img)
    ref_features = vgg_extractor(reference_img)

    # 计算Gram矩阵
    gen_gram = gram_matrix(gen_features)
    ref_gram = gram_matrix(ref_features)

    # 计算差异
    style_loss = mse_loss(gen_gram, ref_gram)
    return style_loss
```

**优势**:
- ✅ 精确的风格度量
- ✅ 适合风格一致性评估
- ✅ 广泛应用于风格迁移

---

## 质量评估工具

### CLIP (Contrastive Language-Image Pre-training)

**应用场景**:
- 风格一致性评估
- 图文匹配度计算

**评估指标**:
- **CLIP相似度**: 评估生成图像与参考图像的风格一致性
- **目标值**: > 0.85

**技术实现**:
```python
from transformers import CLIPProcessor, CLIPModel

# 计算生成图像与参考图像的CLIP相似度
similarity = compute_clip_similarity(generated_img, reference_img)
```

**优势**:
- ✅ 语义级别的相似度
- ✅ 跨模态评估能力
- ✅ 预训练模型可直接使用

---

### FID (Fréchet Inception Distance)

**应用场景**:
- 评估生成图像分布质量
- 视觉保真度度量

**评估指标**:
- **FID分数**: 越低越好
- **目标值**: < 50

**技术原理**:
- 使用Inception网络提取特征
- 计算真实分布与生成分布的距离
- 反映生成质量和多样性

**优势**:
- ✅ 评估整体分布质量
- ✅ 广泛认可的标准指标
- ✅ 适合批量评估

---

### LPIPS (Learned Perceptual Image Patch Similarity)

**应用场景**:
- 感知质量评估
- 细粒度视觉相似度

**评估指标**:
- **LPIPS分数**: 越低越相似
- **目标值**: < 0.2

**技术优势**:
- ✅ 更符合人类感知
- ✅ 比PSNR/SSIM更准确
- ✅ 适合评估编辑质量

**应用示例**:
```python
import lpips

# 计算感知距离
loss_fn = lpips.LPIPS(net='alex')
distance = loss_fn(img1, img2)
```

---

## 开发框架与库

### 深度学习框架

#### PyTorch
- **版本要求**: >= 2.0
- **应用**: 模型微调、推理、训练
- **生态**: 最活跃的扩散模型社区

#### Diffusers (Hugging Face)
- **功能**: 扩散模型工具库
- **支持模型**: Stable Diffusion、Flux、Z-Image等
- **核心组件**:
  - Pipeline封装
  - Scheduler管理
  - LoRA加载

#### PEFT (Hugging Face)
- **功能**: 参数高效微调
- **支持方法**: LoRA、AdaLoRA、Prefix Tuning
- **应用**: 轻量化微调

---

### 量化与优化库

#### bitsandbytes
- **功能**: 8-bit和4-bit量化
- **应用**: QLoRA微调、模型压缩
- **优势**: PyTorch无缝集成

#### Optimum (Hugging Face)
- **功能**: 模型优化工具集
- **支持**: 量化、图优化、推理加速

---

### 图像处理库

#### OpenCV
- **应用**: 图像预处理、边缘提取
- **功能**: Canny边缘、图像变换

#### Pillow (PIL)
- **应用**: 图像读写、格式转换
- **功能**: 基础图像操作

#### Albumentations
- **应用**: 数据增强
- **功能**: 图像变换、增强pipeline

---

## 硬件配置

### 推荐配置

#### 开发与微调
- **GPU**: NVIDIA RTX 4090 (24GB显存)
- **推荐数量**: 1-2卡
- **CPU**: 16核心以上
- **内存**: 64GB+
- **存储**: 1TB NVMe SSD

#### 仅推理
- **GPU**: RTX 4090 (16GB显存已足够)
- **CPU**: 8核心
- **内存**: 32GB
- **存储**: 500GB SSD

---

### 显存需求估算

| 任务 | 模型 | 精度 | 显存需求 |
|------|------|------|---------|
| Z-Image推理 | 6B | FP16 | ~12GB |
| Z-Image微调 | 6B | FP16+LoRA | ~16GB |
| Flux推理 | 12B | 4-bit | ~14GB |
| Flux微调 | 12B | 4-bit+QLoRA | ~18GB |

**优化建议**:
- 使用梯度检查点（Gradient Checkpointing）
- 启用混合精度训练（Mixed Precision）
- 调整batch size和图像分辨率

---

## 数据管理工具

### 核心数据集

#### GUIOdyssey Dataset

**基本信息**:
- **类型**: 大规模移动应用UI截图数据集
- **覆盖范围**: Android/iOS多类型应用
- **数据规模**: 数千至数万级正常界面截图

**数据特征**:
- **设备覆盖**: 主流移动设备截图
- **应用类型**: 电商、社交、工具、游戏等
- **界面状态**: 首页、列表、详情、表单等
- **标注信息**: 界面元素位置、类型、层级关系

**在项目中的价值**:
1. **风格基准库**: 提供各类应用的视觉风格参考
2. **UI组件库**: 包含按钮、输入框、弹窗等常见组件
3. **布局模式**: 展示主流应用的界面布局范式
4. **训练基础**: 作为生成模型的基础训练数据

**数据处理流程**:
```python
# 筛选特定应用的高质量截图
app_screenshots = filter_guiodyssey(
    app_name="taobao",
    min_resolution=(1080, 1920),
    quality_threshold=0.8,
    num_samples=500
)

# 数据增强
augmented_data = augment_ui_screenshots(
    images=app_screenshots,
    techniques=["crop", "resize", "color_jitter"]
)
```

**应用场景**:
- LoRA风格对齐训练
- 参考风格提取
- 布局结构学习
- 正常样本对比

---

### 数据采集

#### Appium
- **功能**: 移动应用自动化测试
- **应用**: 批量截图采集
- **支持平台**: iOS、Android

#### ADB (Android Debug Bridge)
- **功能**: Android设备控制
- **应用**: 截图抓取、UI遍历

---

### 数据标注

#### Label Studio
- **功能**: 数据标注平台
- **应用**: 异常区域标注、分类标注
- **优势**: 支持图像、文本等多种类型

#### CVAT
- **功能**: 计算机视觉标注工具
- **应用**: 界面元素标注、边界框标注

---

### 数据存储

#### Hugging Face Datasets
- **功能**: 数据集管理库
- **优势**: 高效加载、版本管理

#### DVC (Data Version Control)
- **功能**: 数据版本控制
- **应用**: 训练数据管理、版本追踪

---

## 实验管理工具

### Weights & Biases (W&B)
- **功能**: 实验跟踪、可视化
- **应用**:
  - 训练曲线监控
  - 超参数对比
  - 模型版本管理

### MLflow
- **功能**: 机器学习生命周期管理
- **应用**:
  - 实验记录
  - 模型注册
  - 部署管理

### TensorBoard
- **功能**: 训练可视化
- **应用**:
  - Loss曲线
  - 图像生成可视化
  - 资源使用监控

---

## 部署工具

### 推理服务

#### FastAPI
- **功能**: 高性能API框架
- **应用**: 构建生成服务API

#### Gradio
- **功能**: 快速构建Web界面
- **应用**: 原型演示、内部工具

#### TorchServe
- **功能**: PyTorch模型服务化
- **应用**: 生产环境部署

---

### 容器化

#### Docker
- **应用**: 环境隔离、部署一致性
- **镜像**: NVIDIA CUDA官方镜像

#### Docker Compose
- **应用**: 多服务编排
- **场景**: 完整pipeline部署

---

## 技术选型总结

### 核心技术栈（已确定）

```
数据基础: GUIOdyssey Dataset (正常UI截图)
         └── 少量真实异常截图

生成模型: Z-Image Turbo (6B) [首选]
         ├── Z-Image-Edit (编辑)
         └── Flux 12B (备选)

图像编辑: InstructPix2Pix (指令式编辑)
         └── ControlNet Inpainting (精确区域编辑)

微调技术: LoRA (轻量化微调)
         ├── 阶段1: 风格对齐
         ├── 阶段2: 异常注入
         └── QLoRA (量化微调，用于Flux)

控制技术: ControlNet (布局控制)
         ├── Canny (边缘)
         ├── Depth (深度)
         └── Color (颜色)

         IP-Adapter (风格融合)

风格迁移: AdaIN (实时风格迁移)
         ├── NST (高质量风格对齐)
         └── ILVR (扩散模型风格迁移)

少样本学习: DreamBooth (异常模式学习)
           └── Textual Inversion (概念embedding)

质量增强: Real-ESRGAN (超分辨率)
         ├── SwinIR (Transformer超分)
         └── PaddleOCR (文本验证)

评估指标: CLIP相似度、FID、LPIPS
         ├── SSIM (结构相似度)
         └── Style Loss (风格一致性)

UI理解: LayoutLM/LayoutNet (布局理解)
       └── Semantic Segmentation (区域分割)

硬件平台: RTX 4090 (16-24GB显存)

开发框架: PyTorch + Diffusers + PEFT
```

---

### 技术路径选择

#### 主路径：图像编辑模型（推荐）
```
GUIOdyssey正常截图
  ↓
ControlNet + IP-Adapter (保持布局和风格)
  ↓
InstructPix2Pix / ControlNet Inpainting (局部编辑)
  ↓
异常元素注入
  ↓
风格迁移优化 (AdaIN/NST)
  ↓
质量增强 (Real-ESRGAN)
  ↓
文本验证 (PaddleOCR)
  ↓
最终异常截图
```

**优势**:
- ✅ 风格保真度高（基于真实截图）
- ✅ 布局准确（保留原界面结构）
- ✅ 可控性强（精确控制修改区域）

#### 备选路径：文生图模型
```
异常描述文本
  ↓
Z-Image Turbo + LoRA (风格对齐)
  ↓
生成粗糙异常界面
  ↓
风格迁移 (对齐参考应用)
  ↓
细节优化
  ↓
最终异常截图
```

**适用场景**:
- 快速原型验证
- 探索新异常类型
- 缺乏参考截图时

---

### 实施优先级

**Phase 1: 技术验证（当前）**
- ✅ Z-Image Turbo环境搭建
- ✅ 单APP风格对齐测试
- ⏳ LoRA微调pipeline建立

**Phase 2: MVP开发**
- ⏳ 两阶段LoRA微调
- ⏳ 质量评估系统
- ⏳ Flux备选方案集成

**Phase 3: 规模化**
- ⏳ 多APP扩展
- ⏳ 自动化pipeline
- ⏳ 持续优化机制

---

## 相关资源

- [模型选型与工程实施方案](../research/04_模型选型与工程实施方案.md) - 详细技术方案
- [移动UI异常截图生成技术调研](../research/05_移动UI异常截图生成技术调研.md) - 完整实施方案
- [学术研究资源](../references/学术研究.md) - 相关论文
- [开源项目资源](../references/开源项目.md) - 参考项目
- [术语表](./术语表.md) - 技术术语解释

---

**文档版本**: v3.0
**最后更新**: 2026-01-08
**重大变更**:
- 新增图像编辑模型（InstructPix2Pix、ControlNet Inpainting）
- 新增风格迁移技术（AdaIN、NST、ILVR）
- 新增少样本学习技术（DreamBooth、Textual Inversion）
- 新增图像质量增强（Real-ESRGAN、SwinIR）
- 新增OCR与文本处理（PaddleOCR）
- 新增UI理解技术（LayoutLM、Semantic Segmentation）
- 新增评估指标（SSIM、Style Loss）
- 新增GUIOdyssey数据集说明
- 新增技术路径选择指南（图像编辑 vs 文生图）
